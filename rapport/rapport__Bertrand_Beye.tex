%! Author = vadim
%! Date = 1/7/23

% Preamble
\documentclass[11pt]{article}

% Packages
\usepackage{amsmath}
\usepackage[sorting=none,block=ragged,style=numeric-comp]{biblatex}
\usepackage{booktabs}
\usepackage{caption}
\usepackage{dirtytalk}
\usepackage[T1]{fontenc}
\usepackage{float}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[utf8]{inputenc}
\usepackage{subcaption}
\usepackage{xcolor}

% \addbibresource{ref.bib}
\graphicspath{{images/}}
\hypersetup{
  colorlinks=true,
  linkcolor={blue},
  filecolor={Maroon},
  citecolor={Blue},
  urlcolor={blue}
}
\urlstyle{same}

\title{Résistance aux antibiotiques}
\usepackage{etoolbox}
\makeatletter
\providecommand{\subtitle}[1]{
  \apptocmd{\@title}{\par {\large #1 \par}}{}{}
}
\makeatother
\subtitle{Prédiction par apprentissage statistique}
\author{Vadim BERTRAND, Cheikh-Darou BEYE}
\date{9 janvier 2023}

\makeatletter
\renewcommand*{\fps@figure}{H}
\makeatother

% Document
\begin{document}
\maketitle

\renewcommand*\contentsname{Sommaire}{
  \hypersetup{linkcolor=}
  \setcounter{tocdepth}{3}
  \tableofcontents
}
\newpage

\hypertarget{antibioresistance}{%
\section{L'antibiorésistance}\label{antibioresistance}}

  Les antibiotiques sont développés pour contrer les infections dues aux bactéries.
  Certaines bactéries peuvent acquérir une résistance à des antibiotiques, via l'obtention de nouveaux gènes ou par la mutation de gènes existants.
  L'antibiorésistance représente un grand risque pour la santé publique, il est donc important de la limiter.
  Cela passe notamment par une meilleure compréhension des mécanismes de résistances comme l'identification de gènes résistants ou des bactéries résistantes.
  Cette résistance de certaines bactéries à des antibiotiques peut être traitée comme une tâche de classification en apprentissage statistique.

  Dans cette étude nous aurons à notre disposition un jeu de données constitué de 3 matrices de régresseurs et une matrice réponse pour 414 bactéries :
  \begin{itemize}
    \item \textit{X\_gpa}, codant la présence ou l'absence de 16005 gènes,
    \item \textit{X\_nsps}, codant la présence ou l'absence de 72236 mutations génétiques,
    \item \textit{X\_genexp}, représentant l'expression génétique de 6026 gènes ;
    \item \textit{Y}, codant la résistance ou la sensibilité à 5 antibiotiques : la Ceftazidime, la Ciprofloxacine, la Colistine, le Méropenème et la Tobramycine.
  \end{itemize}
  Notre objectif est de prédire la résistance des bactéries aux antibiotiques à partir des régresseurs et d'identifier quelles matrices de régresseurs sont les plus intéressantes pour cette tâche, selon l'antibiotique considéré.

  Dans un premier temps, nous procéderons à une courte exploration des données.
  Puis, nous détaillerons notre démarche : pré-traitements utilisés sur les données, proposition d'approches de réduction de dimension, classifieurs considérés et mise en œuvre via la librairie \textit{scikit-learn}.
  Enfin, nous présenterons les résultats obtenus et nous proposerons quelques pistes d'amélioration.

\hypertarget{exploration-donnees}{%
\section{Exploration des données}\label{exploration-donnees}}

  Avant de nous lancer dans la prédiction de la résistance aux antibiotiques, nous avons souhaité nous pencher sur les données que nous manipulons.

  Naturellement nous avons commencé par observer les types de données que nous manipulons et l'éventuelle présence de données manquantes.
  Sur les 4 matrices à notre disposition, 3 contiennent des données binaires (\textit{Y}, \textit{X\_gpa}, \textit{X\_nsps}) tandis que \textit{X\_genexp} contient des données quantitatives.

  Comme le montre la table~\ref{tab:data}, les matrices de régresseurs ne contiennent pas de données manquantes, mais certaines informations de résistance aux antibiotiques sont manquantes, notamment pour la Ceftazidim avec 20\% de données absentes.
  Etant donné que la taille du jeu de données est réduite, que nous procèderons par la suite à une validation croisée et que nous ne disposerons donc pas d'un jeu de test, nous avons choisi de ne pas imputer les données manquantes afin d'éviter de fausser la généralisation des résultats.
  Par conséquent, les bactéries dont la résistance à un antibiotique est manquante ne seront pas utilisées lors de l'évaluation des classifieurs sur l'antibiotique correspondant.

  Nous pouvons également observer sur la table~\ref{tab:data} que les variables réponses ne sont pas toujours équilibrées : 2 fois plus de bactéries résistantes à la Méropenem, et à l'inverse 2 à 3 fois plus de bactéries susceptibles à la Tobramycin et la Colistin.
  De même, les gènes ou les mutations sont bien plus souvent absentes que présentes.

  \input{tables/data.tex}

  Pour aller un peu plus loin, nous avons représenté nos données regroupées par clustering hiérarchique avec des cartes de chaleur afin de faire apparaître des structures.
  La figure~\ref{fig:gpa_cm} correspondant à la carte de chaleur ainsi obtenue pour la matrice \textit{X\_gpa} permet par exemple de supposer que cette matrice porte de l'information intéressante pour prédire la résistance à la Tobramycin et la Ciprofloxacine, mais probablement moins pour la Colistin.
  Pour celle-ci, nous avons observé par le même biais que la matrice \textit{X\_genexp} sera sûrement indispensable.

  \begin{figure}[H]
    \centering
    \includegraphics[height=10cm,width=\textwidth,keepaspectratio]{gpa_cm}
    \caption{Carte de chaleur du clustering hiérarchique sur les lignes et les colonnes de la matrice \textit{X\_gpa}.
    Les couleurs à gauche des lignes permettent de déterminer si la bactérie est sensible (bleu) ou résistante (rouge) à l'antibiotique, le gris correspond aux données manquantes.}
    \label{fig:gpa_cm}
  \end{figure}

\hypertarget{approche-prediction}{%
\section{Approche pour la prédiction}\label{approche-prediction}}

\hypertarget{pre-traitements}{%
\subsection{Pré-traitements}\label{pre-traitements}}

  Comme expliqué dans la section~\hyperref[exploration-donnees]{\S2}, nous avons fait le choix de supprimer les données manquantes.
  Cette suppression est faite de manière \say{intelligente} en ce sens où les bactéries dont la résistance est absente sont éliminées uniquement pour les antibiotiques concernés et demeurent disponible pour les autres antibiotiques.

  Nous nous sommes ensuite contentés de centrer/réduire les expressions génétiques de la matrice \textit{X\_genexp} grâce au transformateur \textbf{StandardScaler} de \textit{scikit-learn}.

  S'est ensuite posée la question de la mutualisation des informations contenues dans les 3 matrices de classifieurs.
  En traçant les cartes de chaleur de ces matrices, nous avons aperçu que toutes ne sont pas nécessairement pertinentes pour tous les antibiotiques.
  C'est pourquoi nous avons fait le choix de ne pas systématiquement agréger les matrices, mais de considérer les 7 arrangements possibles : 1 seule matrice (3), 2 matrices (3) et les 3 matrices (1).

\hypertarget{reduction-dimension}{%
\subsection{Réduction de la dimensionnalité}\label{reduction-dimension}}

  Nous avons vu que nos matrices de régresseurs contiennent beaucoup de covariables, jusqu'à 94267 lorsque nous les concaténons entres-elles, relativement aux nombres d'observations dont nous disposons.
  Il est donc impératif d'envisager de réduire cette dimensionnalité.
  Cela peut se faire en amont de la tâche de classification, ou alors de manière intégrée en incluant une pénalisation sur les poids du modèle associés aux regresseurs.
  Nous avons considéré les deux approches et nous détaillerons dans cette partie les 3 méthodes que nous avons employées en amont.

\hypertarget{acp-noyau}{%
\subsubsection{ACP (à Noyau)}\label{acp-noyau}}

  L'Analyse en Composantes Principales (ACP) est une approche bien connue permettant de représenter les observations dans un sous-espace vectoriel dont les composantes sont décorrélées.
  Les composantes sont ordonnées en ordre décroissant de variance expliquée, de sorte qu'il est simple d'utiliser le nombre de composantes conservées pour représenter les données comme un hyper-paramètre permettant de plus ou moins réduire la dimensionnalité tout en maximisant le pourcentage de variance expliquée pour un nombre de composantes fixé.

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{pca_var}
      \caption{Variance cumulée exprimée en pourcentage.}
      \label{fig:pca_var}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{pca}
      \caption{Nuage de points selon les 2 premières dimensions.}
      \label{fig:pca_proj}
    \end{subfigure}
    \hfill
    \caption{Représentations de l'ACP avec un noyau linéaire.}
    \label{fig:pca}
  \end{figure}

  Nous avons appliqué l'ACP à notre jeu de données, en considérant tous les arrangements possibles d'utilisation des matrices de descripteurs et comme nous pouvons le voir sur la figure~\ref{fig:pca}, les résultats sont mitigés.
  D'un côté, la figure~\ref{fig:pca_var} ne montre pas de point d'inflexion franc dans la courbe de variance cumulée, ce qui suggère qu'il n'existe pas de point au delà duquel les composantes sont peu importantes.
  En revanche, nous pouvons voir sur la figure~\ref{fig:pca_proj} que la projection dans les deux premières dimensions de l'ACP (en ayant agrégé l'ensemble des matrices de régresseurs) de nos données permet de partiellement séparer les bactéries sensibles et résistantes, ce qui est encourageant en vue de l'étape de classification.

  Par ailleurs, grâce au \textit{kernel-trick} il est possible de mettre en place une variante de l'ACP permettant une réduction de dimensions non linéaire en utilisant divers noyaux.
  Via \textit{scikit-learn}, il suffit alors d'utiliser la classe \textbf{KernelPCA}.

\hypertarget{stability-selection}{%
\subsubsection{Stability selection}\label{stability-selection}}

  La \textit{stability selection} est une approche permettant de corriger l'instabilité de la sélection de variables de l'estimateur Lasso en présence de covariables corrélées.
  Pour ce faire, des estimateurs pénalisés avec la norme $L1$ sont ajustés sur de multiples ré-échantillonnages du jeu de données.
  Chaque estimateur produit un chemin de régularisation le long duquel les poids associés aux covariables les moins importantes pour la tâche de régression ou de classification sont progressivement annulés quand la pénalisation augmente.
  À partir de ces chemins de régularisation, l'estimateur de \textit{stability selection} construit un chemin de stabilité représentant la fréquence de sélection des covariables parmi l'ensemble des estimateurs Lasso.
  Au moyen d'un seuil de stabilité, il est donc possible de sélectionner les variables alors considérées comme \textit{stables}.
  Cette procédure est généralement utilisée comme un estimateur plutôt que comme une méthode de réduction de dimensions, mais nous avons souhaité la tester ainsi (étant donné que nous avons intégré le Lasso aux classifieurs considérés par la suite, l'approche originelle est cependant également employée).

  La \textit{stability selection} n'est pas proposée par \textit{scikit-learn} (uniquement le \textit{bootsrap Lasso}), nous avons donc implémenté notre propre estimateur héritant des classes de bases \textbf{TransformerMixin} et \textbf{BaseEstimator} afin de pouvoir l'utiliser ensuite dans un \textbf{Pipeline}.
  La figure~\ref{fig:stab_path} illustre le chemin de régularité obtenu en utilisant l'ensemble des matrices de régresseurs pour construire la matrice de covariables et avec un seuil de régularité de $0.6$.
  Un tel seuil conduit à conserver environ $1250$ covariables sur plus de $96000$ au départ.

  \begin{figure}[H]
    \centering
    \includegraphics[height=6cm,width=\textwidth,keepaspectratio]{stab_sel}
    \caption{Illustration du chemin de stabilité obtenu par \textit{stability selection}.}
    \label{fig:stab_path}
  \end{figure}

  L'un des inconvénients principal de la \textit{stability selection} est le temps d'ajustement très important en raison du nombre de ré-échantillonnages à effectuer (100 dans notre cas) et de la longueur du chemin de régularisation (fixé à 25).

\hypertarget{tests-multiples}{%
\subsubsection{Tests multiples}\label{tests-multiples}}

  Une autre manière de réaliser la réduction de dimensionnalité pourrait être de considérer que de nombreuses variables sont inutiles pour la prédiction, car leurs distributions entre les bactéries susceptibles ou résistantes est la même.

  Nous pouvons ainsi procéder à une nouvelle sélection de variables s'appuyant cette fois-ci sur deux tests statistiques : le Z-test pour les matrices \textit{X\_gpa} et \textit{X\_snps} et le T-test pour la matrice \textit{X\_genexp}.
  Nous avons utilisé la librairie \textit{statsmodels} qui propose l'implémentation de ces tests.
  En raison du grand nombre de tests réalisés de manière indépendante, il convient d'ajuster les $pvaleurs$.
  Nous avons choisi d'utiliser la procédure de Benjamini-Hochberg permettant de contrôler le FDR (\textit{False Discovery Rate}), plutôt que des procédures contrôlant le FWER (\textit{Family-Wise Error Rate}) afin de découvrir plus de variables statistiquement différentes selon les deux modalités de résistance.
  Nous nous sommes tourné pour cela vers la librairie \textit{MultiPy} qui permet de choisir parmi de nombreuses méthodes d'ajustement.
  L'ensemble de la procédure a été encapsulée dans une classe permettant de l'utiliser comme un transformateur dans un \textbf{Pipeline}.

  Comme le montre la table~\ref{tab:mul_test}, cette approche permet de réduire très fortement le nombre de covariables utilisées par le classifieur, et le niveau $\alpha$ peut-être employé comme un hyper-paramètre permettant de jouer sur le nombre de variables rejetées.

  \input{tables/mul_test.tex}

  Le désavantage que nous voyons à cette approche par tests multiples est que les variables sélectionnées sont potentiellement corrélées.

\hypertarget{classifieurs-consideres}{%
\subsection{Classifieurs considérés}\label{classifieurs-consideres}}

  Nous avons considéré 3 grands types de classifieurs différents : régression logistique, machines à support vectoriel (SVM) et forêts aléatoires.
  Nous avons également utilisé les variantes AdaBoost et Gradient Boosting des forêts aléatoires, ainsi que l'entrainement par descente de gradient pour la régression logistique et la SVM linéaire.

  Dans l'univers \textit{scikit-learn} cela revient à utiliser les classes \textbf{LogisticRegression}, \textbf{SVC}, \textbf{RandomForestClassifier}, \textbf{AdaBoostClassifier}, \textbf{GradientBoostingClassifier} et \textbf{SGDClassifier}.
  Nous verrons dans la section suivante quels hyper-paramètres nous avons fait varier pour ces différents estimateurs, mais pour l'ensemble d'entre eux nous avons spécifié \textit{class\_weight="balanced"} afin de tenir compte du déséquilibre entre les nombres de bactéries sensibles et résistantes.

\hypertarget{mise-oeuvre}{%
\subsection{Mise en œuvre}\label{mise-oeuvre}}

  Comme évoqué précédemment, nous nous sommes reposés sur la librairie \textit{scikit-learn} pour la mise en œuvre de notre étude de prédiction.

  \begin{figure}[H]
    \centering
    \includegraphics[height=6cm,width=\textwidth,keepaspectratio]{pipe}
    \caption{Représentation du \textbf{Pipeline} construit.}
    \label{fig:pipe}
  \end{figure}

  La figure~\ref{fig:pipe} illustre le \textbf{Pipeline} que nous avons utilisé.
  Le premier niveau, \textit{trans\_ind}, applique les pré-traitements de manière distincte pour les différentes matrices de régresseurs.
  Le niveau \textit{sel\_ind} permet de générer les différents arrangements possibles pour l'utilisation des matrices de régresseurs.
  Le troisième niveau correspond à celui de la réduction de dimension.
  Et enfin, le dernier estimateur est le classifieur.

  Ce \textbf{Pipeline} nous permet de \say{facilement} faire varier les différents estimateurs et leurs hyper-paramètres en utilisant la classe \textbf{GridSearchCV} pour trouver la combinaison la plus performante.
  \say{Facilement} car construire une grille d'hyper-paramètres avec notre structure n'est pas si évident que cela, et car le nombre de combinaisons d'hyper-paramètres augmente très vite.
  Nous avons indiqué à l'object \textbf{GridSearchCV} que la métrique à utiliser pour mesurer la performance est la \textit{balanced accuracy} afin de tenir compte du déséquilibre dans les classes à prédire.

  \input{tables/grid_params.tex}

  La table~\ref{tab:grid_params} donne à voir l'ensemble des hyper-paramètres considérés dans la grille de recherche.
  Au total, cela représente $7200$ combinaisons d'estimateurs et d'hyper-paramètres par antibiotique.
  Afin de limiter le temps de recherche des hyper-paramètres, en plus du parallélisme, nous avons utilisé la librairie \textit{scikit-learn-intelex} qui propose des implémentations plus rapides de certains estimateurs pour les processeurs Intel ;
  et nous nous sommes également servi de l'argument \textit{memory} de \textbf{GridSearchCV} qui permet de ne pas ré-ajuster les estimateurs lorsque leurs paramètres d'entrée ne changent pas.
  Malgré cela, la recherche des hyper-paramètres a nécessité plusieurs heures.

\hypertarget{resultats}{%
\section{Résultats}\label{resultats}}

  Dans un premier temps nous nous sommes intéressés à la moyenne et à la déviation standard des scores obtenus par validation croisée pendant la procédure de recherche des hyper-paramètres.
  Nous avons fait figurer sur la table~\ref{tab:res_cv} les meilleurs résultats selon ces critères pour chacun des antibiotiques.
  La table permet également de voir quelles matrices de régresseurs ont alors été utilisées, ainsi que les estimateurs de réduction de dimension et de classification retenus.

  \input{tables/res_cv.tex}

  En terme de scores, nous pouvons immédiatement noter que prédire la résistance à la Colistin semble bien plus compliqué que pour les autres antibiotiques, comme pouvait nous le laisser présager la figure~\ref{fig:gpa_cm}.
  La Ceftazidim vient ensuite, puis la Ciprofloxacin et la Meropenem dont les performances de prédiction sans assez proches, tandis que la Tobramycin apparait comme l'antibiotique auquel la résistance est la plus prévisible.
  En parallèle des scores moyens, nous pouvons être relativement satisfait de la déviation standard de la \textit{balanced accuracy} qui est inférieure ou égale à $0.05$, exception faite de la Colistin.

  À la vue des indications de présence ou d'absence des matrices de régresseurs, \textit{X\_gpa} semble importante dans la prédiction de l'ensemble des résistances, \textit{X\_genexp} a été ignorée uniquement dans le cas de la Ciprofloxacin et \textit{X\_snps} serait celle la moins souvent utile car conservée deux fois seulement.
  Pour approfondir ces observations nous avons observé le pourcentages de sélection des matrices de régresseurs parmi les 10 meilleures architectures pour chaque antibiotique.
  Nous pouvons voir sur la table~\ref{tab:res_x} qu'il est confirmé que \textit{X\_snps} est bien nécessaire pour prédire la résistance à la Ciprofloxacin mais très peu utile pour les autres antibiotiques.
  En revanche, l'importance prépondérante de \textit{X\_gpa} pour l'ensemble des antibiotiques est nuancée, notamment en comparaison avec celle de \textit{X\_genexp} qui est sélectionnée $100\%$ du temps 3 fois, contre 2 fois pour \textit{X\_gpa}.
  Ainsi \textit{X\_genexp} semble absoluement indispensable pour la prédiction de la Tobramycin, la Colistin et la Ceftazidim ;
  tandis que \textit{X\_gpa} le serait également pour la Tobramycin, et pour la Meropenem.

  \input{tables/res_x.tex}

  La table~\ref{tab:res_x} montre Le choix de considérer la \textit{stability selection} et les tests multiples pour réduire la dimensionnalité semble aussi avoir été payant, étant donné qu'ils sont très fortement représentés parmi les meilleures architectures, au contraire de l'ACP.
  Il est visible que la \textit{stability selection} est plébiscitée dans les cas de la Colistin et la Tobramycin, tandis que les tests multiples le sont pour la Meropenem.

  Pour tenter de comprendre un peu plus les forces et les faiblesses de nos modèles de prédictions, nous avons généré les matrices de confusion entre les classes attendues et celles prédites.
  Dans la plupart des cas il n'est pas apparu de déséquilibre dans les fausses prédictions entre classe résistante et sensible, mis à part pour la Colistin et la Méropenem dont nous avons donc représenté les matrices sur la figure~\ref{fig:conf_mat}.
  Il semble sur~\ref{fig:conf_mat_colis} que notre modèle a eu plus de difficultés à correctement classifier la susceptibilité à la Colistin que la résistance, ce qui peut-être préférable selon l'objectif visé.
  A l'inverse,~\ref{fig:conf_mat_merop} montre que pour la Meropenem c'est la détection des bactéries résistantes qui a causé le plus de problème, mais dans des proportions moindres qu'avec la Colistin.
  Dans les deux cas, cela peut s'expliquer par le fort déséquilibre entre bactéries sensibles et résistantes pour ces antibiotiques, mais ce déséquilibre était également présent pour la Tobramycin dont la matrice de confusion est équilibrée.

  \begin{figure}[H]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{conf_mat_colis}
      \caption{Pour la Colistin.}
      \label{fig:conf_mat_colis}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
      \centering
      \includegraphics[width=\textwidth]{conf_mat_merop}
      \caption{Pour la Meropenem.}
      \label{fig:conf_mat_merop}
    \end{subfigure}
    \hfill
    \caption{Matrices de confusion.}
    \label{fig:conf_mat}
  \end{figure}

\hypertarget{conclusion}{%
\section{Conclusion}\label{conclusion}}

  Afin de prédire au mieux la résistance d'environ $400$ bactéries à $5$ antibiotiques différents à partir de $3$ matrices de régresseurs, nous avons développé un \textbf{Pipeline} doté de plusieurs couches permettant d'appliquer des pré-traitements distincts, de sélectionner ou non les matrices de régresseurs, de réduire la dimensionnalité des covariables utilisées par différentes approches et enfin d'appliquer plusieurs classifieurs.
  Les meilleures combinaisons et leurs hyper-paramètres ont ensuite été ajustés par validation croisée afin de généraliser au mieux les résultats finaux, et en considérant comme critère la \textit{balanced accuracy} pour tenir compte du déséquilibre des classes à prédire.

  Les scores obtenus par validation croisée ont montré que la Colistin est l'antibiotique pour lequel la prédiction à la résistance s'est avéré la plus compliquée, avec une \textit{balanced accuracy} moyenne de seulement $0.73$ et une déviation de $0.06$.
  Nous considérons en revanche que la prédiction pour les autres antibiotiques est plutôt bonne, voir très bonne en ce qui concerne la Tobramycin.

  Il est apparu que la prédiction de la résistance pour tous les antibiotiques ne nécessitaient pas les mêmes types d'informations sur les bactéries.
  Ainsi, la présence ou l'absence de gènes s'est avérée capitale pour la Meropenem et la Tobramycin, tandis que ce sont les mutations génétiques qui ont été indispensables pour la Ciprofloxacin.
  Les informations sur l'état cellulaire \say{courant} des bactéries a-t-elle été absoluement nécessaire pour la Ceftazidim, et surtout la Colistin, et s'est trouvée être un excellent complément pour la Tobramycin. \\

  Pour finir, nous avons identifié quelques pistes intéressantes et des questionnements sur les résultats obtenus.

  Tout d'abord, il aurait peut-être été bon de se pencher sur l'impact sur la dimensionnalité des différentes méthodes de réduction de dimension et sur le lien éventuel avec les performances en classification.

  Nous aurions aussi aimé inclure un estimateur réalisant un vote entre les prédictions de plusieurs classifieurs mais nous n'avons pas eu le temps de répondre à la question du choix des classifieurs utilisés pour le vote : les $n$ meilleurs, les meilleurs sur chacun des sous-ensembles de validation, ...
  Nous étions également contraints par les temps d'ajustement des modèles.

  De plus, afin de réduire ces temps d'ajustement, nous aurions peut-être pu utiliser la classe \textbf{HalvingGridSearchCV} permettant d'ajuster les hyper-paramètres en allouant peu de ressources au début de la recherche et en éliminant les combinaisons les plus mauvaises au fur et à mesure que plus de ressources sont allouées.
  Notre souci avec cette technique a été le fort déséquilibre dans les classes à prédire pour les premières itération de la recherche.

  Par ailleurs, nous ne nous sommes pas interrogés sur les types de classifieurs les plus utilisés pour les différents antibiotiques.
  Cela aurait pu nous donner des indications sur les mécanismes de classification les plus performants.

  Enfin, nous avons décidé de ne pas utiliser de réseaux de neurones en raison du fort risque de sûr-apprentissage dû au faible nombre d'observations à notre disposition et du grand nombre d'hyper-paramètres à considérer avec ce types de modèles.
  De plus, le coût calculatoire s'en serait encore trouvé augmenté.

\end{document}